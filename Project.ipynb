{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERM PROJECT [ROBT407]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed by Anuar Maratkhan, Ainura Karabayeva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method of Linear Regression is based on minimization of square root error: <br/> <h3 align=\"center\">$\\underset{w}{min}\\sum\\limits_{n=1}^N[y_{n}-(w^{T}x_{n})]^2$</h3><br/>\n",
    "We have used the following algorithm:<br/>\n",
    "1: Constructing the matrix $X$ (input data matrix) and vector $y$ (target vector) from the data set, including $x_{0}=1$ (the column of 1s) <br/>\n",
    "2: Compute the pseudo-inverse $X^{t}=(X^{T}X)^{-1}X^{T}$ of the matrix $X$<br/>\n",
    "3: Return $w_{lin}=X^{t}y$ <br/>\n",
    "\n",
    "For 1st task we implemented four functions: generating random data set, finding error of the model, pocket algorithm, and linesr regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generation random data set with giving size\n",
    "def generate_data(size):\n",
    "    w_true = random.randint(1,10,size=2) #coefficients of Xs \n",
    "    b_true = random.randint(1,10) #bias term\n",
    "    \n",
    "    d = 2\n",
    "    X = random.uniform(-1,1,(size,d))*10 \n",
    "\n",
    "    Y = zeros(20)\n",
    "    \n",
    "#calculating final hypothesis\n",
    "#here the parameters of target function can be extracted: \n",
    "#slope=-w_true[0]/w_true[1], bias=-b_true/w_true[1]\n",
    "\n",
    "    h = X.dot(w_true) + b_true\n",
    "    labels = (h > 0)*1\n",
    "\n",
    "    # randomly choose 10\n",
    "    indexes = random.randint(size, size=10)\n",
    "    # flip chosen Ys\n",
    "    for i in indexes:\n",
    "        if (labels[i] == 1):\n",
    "            labels[i] = 0\n",
    "        else:\n",
    "            labels[i] = 1\n",
    "    Y = labels\n",
    "    \n",
    "    a=ones(size)    #to get bias coordinate x_0=1\n",
    "    a1=a.reshape(size,1)\n",
    "    X1=hstack((a1,X)) #input data matrix\n",
    "    \n",
    "    return X1, Y, w_true, b_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_error(x, w, y):\n",
    "    E = 0.0\n",
    "    for i in range(len(x)):\n",
    "        ypred = dot(x[i],w)\n",
    "        if(ypred > 0 and y[i] == -1): #predicted wrongly as 1st class\n",
    "            E += 1\n",
    "        elif(ypred <= 0 and y[i] == 1): #predicted wrongly as 2nd class\n",
    "            E += 1\n",
    "    return E/x.size #find Error term by finding mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# oursize is the number of obsevations((x1, x2)), ntimes is the number of iterations of pocket algorithm\n",
    "#w is the initial weights\n",
    "\n",
    "def pocket(x, y, w, ntimes): \n",
    "    \n",
    "    t = [] #array of number of updates\n",
    "    tt = 0 #current update number\n",
    "    #w= zeros(3)\n",
    "    w_new=[]\n",
    "    E=[]\n",
    "    E_val=0.0\n",
    "    \n",
    "    for ii in range (ntimes):\n",
    "        \n",
    "        y_wr_collection = [] #saves indeces of the wrong predicted y\n",
    "        ypredict=[]\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            \n",
    "            if dot(x[i],w)>0:\n",
    "                ypredict.append(1)\n",
    "            else: ypredict.append(0)\n",
    "            \n",
    "            if ypredict[i] != y[i]:\n",
    "                y_wr_collection.append(i)\n",
    "                \n",
    "        #randomly choose the index of wrong classified x\n",
    "        pick_random = np.random.randint(len(y_wr_collection)) \n",
    "        \n",
    "        #new weight\n",
    "        w_new = w + (y[pick_random]-ypredict[pick_random]) * x[pick_random]\n",
    "\n",
    "        E_old = find_error(x, w, y)\n",
    "        E_new = find_error(x, w_new, y)\n",
    "\n",
    "        if (E_new < E_old): #compare old and new Error\n",
    "\n",
    "            E.append(E_new) \n",
    "            t.append(tt)\n",
    "            tt += 1\n",
    "            w = copy(w_new) #update weight to new weight\n",
    "            E_val=E_new\n",
    "        \n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(x, y): \n",
    "    \n",
    "    #to reshape in order to be able to compute dot product\n",
    "    y_new=y.reshape(len(y),1)\n",
    "    \n",
    "    INV = np.linalg.inv(dot(x.T,x)) #inverse\n",
    "    pseudo_inv_x=dot(INV, x.T)\n",
    "    w=dot(pseudo_inv_x,y_new)\n",
    "    \n",
    "    E=find_error(x, w, y)\n",
    "    w1=w.reshape(3)\n",
    "    \n",
    "    return w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Generating a training data set of size 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,y_train,w_true_train, b_true_train=generate_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Generating a test data set of size 1000 of the identical nature of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test,y_test,w_true_test, b_true_test=generate_data(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Run of Pocket algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=zeros(3) #set initial weight vector of 0s\n",
    "w_pocket=pocket(x_train,y_train,w,1000)\n",
    "print ('Weights are: ',w_pocket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Run of Linear Regression algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lin=lin_reg(x_train, y_train)\n",
    "print ('Weights are: ',w_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_true=-w_true_train[0]/w_true_train[1]\n",
    "bias_true=-b_true_train/w_true_train[1]\n",
    "print('Slope of target function is ',slope_true, 'bias term is ',bias_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_pocket = -w_pocket[1]/w_pocket[2]\n",
    "slope_pocket = -w_pocket[0]/w_pocket[2]\n",
    "print ('Final hypothesis of Pocket algorithm is ', 'g=',slope_pocket,'x','+',bias_pocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lin = -w_lin[1]/w_lin[2]\n",
    "b_lin = -w_lin[0]/w_lin[2]\n",
    "print (a_lin,b_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here can be clearly seen that the slope values of both Pocket and Linear Reagression algorithms are very close to the slope of target function. However, the bias terms are different for both. It means that the lines approximated by two different algorithms have nearly equal slope but the location with respect to the origin are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculating $E_{test}(w_{pocket})$ and $E_{test}(w_{lin})$ of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_pocket=find_error(x_test, w_pocket, y_test)\n",
    "E_pocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_lin=find_error(x_test, w_lin, y_test)\n",
    "E_pocket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Repeat the experiment 100 times with new data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new,y_new,w_true_new, b_true_new=generate_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_pocket_new=zeros(100)\n",
    "E_lin_new=zeros(100)\n",
    "w_new=zeros(3)\n",
    "n=zeros(100)\n",
    "\n",
    "for i in range (100):\n",
    "    \n",
    "    E_pocket_new[i]=find_error(x_new, w_pocket, y_new)\n",
    "    E_lin_new[i]=find_error(x_new, w_lin, y_test)\n",
    "    \n",
    "    n[i]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(n,E_pocket_new*100, c='red')\n",
    "scatter(n,E_lin_new*100, c=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(E_pocket_new*100,E_lin_new*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be clearly seen that after repeating experiment 100 times, the algorithm of Linear Regression is more efficient than Pocket. However, both algorithms gives very low error terms (less than 5%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pocket Algorithm**<br/>\n",
    "*Results:* <br/>\n",
    "1. It was seen that Pocket Algorithm generates very close parameters (slope and bias) to the target function. \n",
    "2. The Error terms were relatively low, no more than 10%. \n",
    "3. Error term obtained from test set (n=1000) by implemeting weights from training set is identical to the Error term of Linear Regression. <br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problems: <br/>*\n",
    "1. The data is not completely separable, that is why it is impossible to get E_pocket = 0\n",
    "2. Pocket algorithm is more time consuming than Linear Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**<br/>\n",
    "*Results:*<br/>\n",
    "1. Efficiently fast and easy calculate weights with low Error terms.\n",
    "2. Get very close parameters to the target function. However, the bias is much more different. It means that the obtained line is located in a different place than target function. Line of Pocket algorithm is closer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problems:*<br/>\n",
    "1. Calculating pseudo-inverse require matrix being invertible which might not be true for some data sets. Thus, various other function might be implemented, but to find common function which will work for all cases is very hard. \n",
    "2. Linear Regression is limited to linear relationship. We first assume that classification might be done by estimating a line. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gradient Descent for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(data):\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    \n",
    "    # random sampling\n",
    "    train_size = int(0.8*X.shape[0])\n",
    "    train_ind = random.sample(range(0,150),120) # unique random indices\n",
    "    X_train = X[train_ind]\n",
    "    y_train = y[train_ind]\n",
    "    \n",
    "    test_ind = list(set(range(0,150))-set(train_ind))\n",
    "    X_test = X[test_ind]\n",
    "    y_test = y[test_ind]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, d = X_train.shape\n",
    "test_samples = X_test.shape[0]\n",
    "\n",
    "train_ind = random.sample(range(0,120),120)\n",
    "test_ind = random.sample(range(0,30),30)\n",
    "\n",
    "epochs = 2000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "weights = np.zeros(d+1)\n",
    "\n",
    "E_in = []\n",
    "E_out = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    E_in_total = 0\n",
    "    for ind in train_ind:\n",
    "        extended_X_train = np.append(X_train[ind],1)\n",
    "        cross_entropy_error = np.log(1+np.exp(-y_train[ind]*2*np.dot(weights.T, extended_X_train)))\n",
    "        weights = weights + learning_rate * cross_entropy_error # does not work with minus sign!\n",
    "        \n",
    "        E_in_total += cross_entropy_error\n",
    "    E_in_average = E_in_total / train_samples\n",
    "    E_in.append(E_in_average)\n",
    "    \n",
    "    E_out_total = 0\n",
    "    for ind in test_ind:\n",
    "        extended_X_test = np.append(X_test[ind],1)\n",
    "        cross_entropy_error = np.log(1+np.exp(-y_test[ind]*2*np.dot(weights.T, extended_X_test)))\n",
    "        \n",
    "        E_out_total += cross_entropy_error\n",
    "    E_out_average = E_out_total / test_samples\n",
    "    E_out.append(E_out_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "plt.plot(range(epochs), E_in, 'b', label='train')\n",
    "plt.plot(range(epochs), E_out, 'r', label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**<br/>\n",
    "*Results:*<br/> \n",
    "1. By repeating experiment the Error of train set decreases faster (but not always the case) than the Error of test set. It can be explained by that the training set is bigger than test set, so the reduction of Error occures faster. \n",
    "2. The Error is higher than average Error of Linear Regression and Pocket algorithm. \n",
    "3. The early stopping would be perfect here because the error converges approximately after 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Limitations:*<br/>\n",
    "1. Might not perform well for very large feature space. We see that the algorithm shows higher Error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Practical design of a learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.images.shape)\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error based on Euclidean distance from each point to prediction line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_error_lin(x, w, y):\n",
    "    E = 0.0\n",
    "    E=dot(y.T,y)-2*dot(w.T,dot(x.T,y))+dot(dot(w.T, x.T),dot(x,w))\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(X_train, X_test, y_train, y_test):\n",
    "    w = np.linalg.pinv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "        \n",
    "    return find_error_lin(X_test, w, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def log_reg(X_train, X_test, y_train, y_test):\n",
    "    train_samples, d = X_train.shape\n",
    "    test_samples = X_test.shape[0]\n",
    "\n",
    "    train_ind = random.sample(range(0,train_samples),train_samples)\n",
    "    test_ind = random.sample(range(0,test_samples),test_samples)\n",
    "\n",
    "    epochs = 100\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    weights = np.zeros(d+1)\n",
    "\n",
    "    E_in = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        E_in_total = 0\n",
    "        for ind in train_ind:\n",
    "            extended_X_train = np.append(X_train[ind],1)\n",
    "            cross_entropy_error = np.log(1+np.exp(-y_train[ind]*2*np.dot(weights.T, extended_X_train)))\n",
    "            weights = weights + learning_rate * cross_entropy_error # does not work with minus sign!\n",
    "\n",
    "            E_in_total += cross_entropy_error\n",
    "        E_in_average = E_in_total / train_samples\n",
    "        E_in.append(E_in_average)\n",
    "\n",
    "    E_out_total = 0\n",
    "    for ind in test_ind:\n",
    "        extended_X_test = np.append(X_test[ind],1)\n",
    "        cross_entropy_error = np.log(1+np.exp(-y_test[ind]*2*np.dot(weights.T, extended_X_test)))\n",
    "\n",
    "        E_out_total += cross_entropy_error\n",
    "    E_out_average = E_out_total / test_samples\n",
    "\n",
    "    return E_out_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_folds(X, y, folds=10):\n",
    "    fold_size = int(X.shape[0] / folds)\n",
    "    folds_dict = {}\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for i in range(folds-1):\n",
    "        X_fold = X[fold_size*i : fold_size*i+fold_size]\n",
    "        y_fold = y[fold_size*i : fold_size*i+fold_size]\n",
    "        X_list.append(X_fold)\n",
    "        y_list.append(y_fold)\n",
    "        \n",
    "    # take rest of the data\n",
    "    X_fold = X[fold_size*(folds-1):]\n",
    "    y_fold = y[fold_size*(folds-1):]\n",
    "    X_list.append(X_fold)\n",
    "    y_list.append(y_fold)\n",
    "    \n",
    "    folds_dict['X'] = X_list\n",
    "    folds_dict['y'] = y_list\n",
    "    \n",
    "    return folds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = split_folds(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_folds = np.array(folds['X'])\n",
    "y_folds = np.array(folds['y'])\n",
    "\n",
    "E_total_linear = []\n",
    "E_total_logistic = []\n",
    "\n",
    "for fold_num in range(len(folds['X'])):\n",
    "    X_test = X_folds[fold_num]\n",
    "    y_test = y_folds[fold_num]\n",
    "\n",
    "    X_temp = np.delete(X_folds, fold_num)\n",
    "    y_temp = np.delete(y_folds, fold_num)\n",
    "\n",
    "    X_train = np.concatenate([X_temp[0]])\n",
    "    for i in range(1,len(X_temp)):\n",
    "        X_train = np.concatenate([X_train, X_temp[i]])\n",
    "\n",
    "    y_train = np.concatenate([y_temp[0]])\n",
    "    for i in range(1,len(y_temp)):\n",
    "        y_train = np.concatenate([y_train, y_temp[i]])\n",
    "        \n",
    "    E_out_linear = lin_reg(X_train, X_test, y_train, y_test)\n",
    "    E_total_linear.append(E_out_linear)\n",
    "    \n",
    "    E_out_logistic = log_reg(X_train, X_test, y_train, y_test)\n",
    "    E_total_logistic.append(E_out_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_total_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the error is pretty variative. That is because we have different data in each cross validation step. The model errors are different for tests on each of the folds by being trained on rest 9 folds. Thus, using cross validation is suggested because it will show more accurate data (an estimate of the generalization error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_total_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(E_total_linear)/len(E_total_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(E_total_logistic)/len(E_total_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: errors are different because error function are different. Linear regression uses Euclidean distance based error function, and logistic regression uses cross entropy error function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = split_folds(X, y, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_folds = np.array(folds['X'])\n",
    "y_folds = np.array(folds['y'])\n",
    "\n",
    "E_total_linear = []\n",
    "E_total_logistic = []\n",
    "\n",
    "for fold_num in range(len(folds['X'])):\n",
    "    X_test = X_folds[fold_num]\n",
    "    y_test = y_folds[fold_num]\n",
    "\n",
    "    X_temp = np.delete(X_folds, fold_num)\n",
    "    y_temp = np.delete(y_folds, fold_num)\n",
    "\n",
    "    X_train = np.concatenate([X_temp[0]])\n",
    "    for i in range(1,len(X_temp)):\n",
    "        X_train = np.concatenate([X_train, X_temp[i]])\n",
    "\n",
    "    y_train = np.concatenate([y_temp[0]])\n",
    "    for i in range(1,len(y_temp)):\n",
    "        y_train = np.concatenate([y_train, y_temp[i]])\n",
    "        \n",
    "    E_out_linear = lin_reg(X_train, X_test, y_train, y_test)\n",
    "    E_total_linear.append(E_out_linear)\n",
    "    \n",
    "    E_out_logistic = log_reg(X_train, X_test, y_train, y_test)\n",
    "    E_total_logistic.append(E_out_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(E_total_linear)/len(E_total_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(E_total_logistic)/len(E_total_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the observations, we see that the less folds we have, the higher the error is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = split_folds(X, y, folds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_folds = np.array(folds['X'])\n",
    "y_folds = np.array(folds['y'])\n",
    "\n",
    "E_total_linear = []\n",
    "E_total_logistic = []\n",
    "\n",
    "for fold_num in range(len(folds['X'])):\n",
    "    X_test = X_folds[fold_num]\n",
    "    y_test = y_folds[fold_num]\n",
    "\n",
    "    X_temp = np.delete(X_folds, fold_num)\n",
    "    y_temp = np.delete(y_folds, fold_num)\n",
    "\n",
    "    X_train = np.concatenate([X_temp[0]])\n",
    "    for i in range(1,len(X_temp)):\n",
    "        X_train = np.concatenate([X_train, X_temp[i]])\n",
    "\n",
    "    y_train = np.concatenate([y_temp[0]])\n",
    "    for i in range(1,len(y_temp)):\n",
    "        y_train = np.concatenate([y_train, y_temp[i]])\n",
    "        \n",
    "    E_out_linear = lin_reg(X_train, X_test, y_train, y_test)\n",
    "    E_total_linear.append(E_out_linear)\n",
    "    \n",
    "    E_out_logistic = log_reg(X_train, X_test, y_train, y_test)\n",
    "    E_total_logistic.append(E_out_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(E_total_linear)/len(E_total_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(E_total_logistic)/len(E_total_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the observations, we can clearly see that the more folds we have, the less error is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave one out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = split_folds(X, y, folds=X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_folds = np.array(folds['X'])\n",
    "y_folds = np.array(folds['y'])\n",
    "\n",
    "E_total_linear = []\n",
    "E_total_logistic = []\n",
    "\n",
    "for fold_num in range(len(folds['X'])):\n",
    "    X_test = X_folds[fold_num]\n",
    "    y_test = y_folds[fold_num]\n",
    "\n",
    "    X_temp = np.delete(X_folds, fold_num, axis=0)\n",
    "    y_temp = np.delete(y_folds, fold_num, axis=0)\n",
    "\n",
    "    X_train = np.concatenate([X_temp[0]])\n",
    "    for i in range(1,len(X_temp)):\n",
    "        X_train = np.concatenate([X_train, X_temp[i]])\n",
    "\n",
    "    y_train = np.concatenate([y_temp[0]])\n",
    "    for i in range(1,len(y_temp)):\n",
    "        y_train = np.concatenate([y_train, y_temp[i]])\n",
    "        \n",
    "    E_out_linear = lin_reg(X_train, X_test, y_train, y_test)\n",
    "    E_total_linear.append(E_out_linear)\n",
    "    \n",
    "    E_out_logistic = log_reg(X_train, X_test, y_train, y_test)\n",
    "    E_total_logistic.append(E_out_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(E_total_linear)/len(E_total_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(E_total_logistic)/len(E_total_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "max(cross_val_score(model, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid = { 'C' : C}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=10)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, test_score = validation_curve(LogisticRegression(), X, y, \"C\", C, cv=10)\n",
    "\n",
    "plt.plot(C, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(C, np.median(test_score, 1), color='red', label='validation score')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('C (log scaled)')\n",
    "plt.ylabel('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid = { 'C' : C}\n",
    "grid = GridSearchCV(LinearSVC(), param_grid, cv=10)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, test_score = validation_curve(LinearSVC(), X, y, \"C\", C, cv=10)\n",
    "\n",
    "plt.plot(C, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(C, np.median(test_score, 1), color='red', label='validation score')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('C (log scaled)')\n",
    "plt.ylabel('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.arange(10)\n",
    "param_grid = {'degree' : degree}\n",
    "grid = GridSearchCV(SVC(kernel='poly'), param_grid, cv=10)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, test_score = validation_curve(SVC(kernel='poly'), X, y, \"degree\", degree, cv=10)\n",
    "\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(test_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from experiments above, the results are as follows:\n",
    "\n",
    "Linear Regression score: 0.6717421507323188\n",
    "\n",
    "Best performed Logistic Regression score: 0.9376739009460211\n",
    "\n",
    "Best performed Linear SVM score: 0.9393433500278241\n",
    "\n",
    "Best performed polynomial kernel SVM score: 0.9788536449638287"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, to conclude, the experiments show the lowest results for Linear Regression (which does not have any parameters), Logistic Regression and Linear SVM are showing approximately same good results, but the best results are obtained by utilizing SVM with polynomial kernel, which is nearly 98%. However, there is a little tradeoff between execution time of each cell above, and their efficiencies: the best performed model, polynomial SVM is being trained a lot more in terms of time relative to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the probable limitation in terms of computation time of each cells above may be large dataset size, with some number of parameters, and cross validations. That means model has to be evaluated that much times. In other words, computation complexity grows as each of the features (cross validation folds, number of parameters, dataset size) grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of bias-variance tradeoff, only logistic regression is being overfitted on digits dataset because as we see, the higher C parameter, the lower validation accuracy, which is not seen from training accuracy. And if validation accuracy starts lowering relative to training accuracy as complexity of the model grows, we say that the model has overfitted.\n",
    "\n",
    "Other two models, which are Support Vector Machines, does not overfit digits data. That may be seen from the two approximately same curves: training and validation. As training grows, validation also grows, and as training lowers, validation also lowers, which is perfect and does not overfit or underfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statement: each student has contributed to the project equally by implementing each of the parts individually. After individual implementation, we just compared the results, and have taken the best of the implementations. However, Ainura has contributed more to the report of first two sections, and Anuar has contributed more to the last section of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
